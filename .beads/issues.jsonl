{"id":"webidl-1","title":"Migrate parser serializer to use infra.json","description":"Goal: Replace 1099 lines of custom JSON serialization with infra.json. Tasks: 1) Create AST to InfraValue converter (~450 LOC, 1-2 days). 2) Refactor serializer to use infra.json (~50 LOC, 2-3 hours). 3) Add tests (~200 LOC, 1 day). 4) Verify parser output unchanged (2-3 hours). Success: Net -850 LOC, all 333 IDL files parse, zero leaks. Effort: 3-4 days. Benefits: Eliminate manual JSON code, consistent with Infra standard, easier maintenance.","status":"closed","priority":1,"issue_type":"feature","created_at":"2025-10-31T20:10:34.677609-04:00","updated_at":"2025-10-31T20:19:23.73149-04:00","closed_at":"2025-10-31T20:19:23.73149-04:00"}
{"id":"webidl-2","title":"Add BufferedAsyncSequence with infra.Queue for async buffering","description":"## Goal\nAdd buffering support to AsyncSequence using infra.Queue(T) for producer/consumer pattern.\n\n## Current State\n- AsyncSequence uses iterator-only model\n- No built-in buffering mechanism\n- Producer must be synchronous with consumer\n\n## Target State\n- AsyncSequence can buffer values in infra.Queue\n- Producer can push values asynchronously\n- Consumer pulls from queue when ready\n- Backpressure handling via queue size\n\n## Implementation Tasks\n\n### 1. Add BufferedAsyncSequence (~100 LOC, 4-5 hours)\n- **File**: src/types/async_sequences.zig (enhance)\n- Create BufferedAsyncSequence(T) type using infra.Queue(T)\n- Implement push() for producer (enqueue)\n- Implement next() for consumer (dequeue)\n- Implement close() to signal end of sequence\n- Track buffered count and closed state\n\n### 2. Add Producer/Consumer Tests (~150 LOC, 3-4 hours)\n- **File**: src/types/async_sequences.zig (add tests)\n- Test producer/consumer pattern\n- Test backpressure (buffer size tracking)\n- Test close prevents further pushes\n- Test async buffering scenarios\n\n## Example API\n```zig\nvar seq = BufferedAsyncSequence(u32).init(allocator);\ndefer seq.deinit();\n\n// Producer: Push values\ntry seq.push(1);\ntry seq.push(2);\ntry seq.push(3);\nseq.close();\n\n// Consumer: Read values\nconst v1 = try seq.next(); // 1\nconst v2 = try seq.next(); // 2\nconst v3 = try seq.next(); // 3\nconst v4 = try seq.next(); // null (end)\n```\n\n## Success Criteria\n✅ Producer/consumer pattern works correctly\n✅ Buffering handles backpressure\n✅ FIFO semantics maintained via infra.Queue\n✅ Zero memory leaks\n✅ Integration tests with realistic async scenarios\n\n## Effort Estimate\n**Total**: 1 day (~250 LOC)\n\n## Benefits\n- Real async buffering support\n- FIFO semantics via infra.Queue (spec-compliant)\n- Backpressure handling\n- Ready for Fetch Streams, ReadableStream integration\n\n## Use Cases\n- Fetch Streams API - Stream response body chunks\n- File System Access API - Stream directory entries\n- WebGPU - Stream large buffer reads\n- Any API producing data over time\n\n## References\n- WebIDL async iterable: https://webidl.spec.whatwg.org/#idl-async-iterable\n- Current implementation: src/types/async_sequences.zig\n- Infra Queue: ~/.cache/zig/p/infra-0.2.0-*/src/queue.zig","status":"closed","priority":2,"issue_type":"feature","created_at":"2025-10-31T20:10:35.18052-04:00","updated_at":"2025-10-31T20:19:21.97676-04:00","closed_at":"2025-10-31T20:19:21.97676-04:00"}
{"id":"webidl-3","title":"Investigate stack-based parser with infra.Stack","description":"Goal: Investigate stack-based parser using infra.Stack vs current recursive approach. Tasks: 1) Create stack parser prototype (~400 LOC, 2-3 days). 2) Benchmark vs recursive (~100 LOC, 4-5 hours). 3) Decision point. Success: Clear decision with rationale. Effort: 3-4 days. Risk: LOW PRIORITY - only needed if stack overflow or error recovery becomes issue. Current recursive parser works fine.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-31T20:10:35.798857-04:00","updated_at":"2025-10-31T20:11:47.39193-04:00"}
{"id":"webidl-4","title":"Evaluate infra.ListWithCapacity for ObservableArray optimization","description":"Goal: Determine if infra.ListWithCapacity can replace custom inline storage in ObservableArray. Current: Custom inline storage (first 4 items) then ArrayList (~100 LOC). Tasks: 1) Analyze current optimization (2 hours). 2) Create prototype with ListWithCapacity (~200 LOC, 1 day). 3) Benchmark custom vs infra (~100 LOC, 4-5 hours). 4) Document decision. Success: Performance within 5%, clear decision documented. Effort: 2 days. Outcome: Either eliminate ~100 LOC or justify custom approach.","status":"open","priority":3,"issue_type":"task","created_at":"2025-10-31T20:10:36.394179-04:00","updated_at":"2025-10-31T20:11:51.461592-04:00"}
